{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesis S4 (random 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. stitch frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import stitch_frames\n",
    "import os\n",
    "import random\n",
    "\n",
    "dataset_dir = '/mnt/data1/jiali/avsbench_data/Single-source/s4_data/visual_frames'\n",
    "\n",
    "for split in ['test', 'train', 'val']:\n",
    "    base_dir = os.path.join(dataset_dir, split)\n",
    "    entries = os.listdir(base_dir)\n",
    "    categories = [entry for entry in entries if '.DS_Store' not in entry]\n",
    "    for temp_cate in categories:\n",
    "        print(split, temp_cate)\n",
    "        video_list = os.listdir(os.path.join(base_dir, temp_cate))\n",
    "        for temp_video in video_list:\n",
    "            input_video_path = os.path.join(base_dir, temp_cate, temp_video)\n",
    "\n",
    "            stitch_frames(base_dir, input_video_path, split, save_floder_name = '/avsbench_synthesis_visual_random4/', num_with_audio_and_mask=random.randint(1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. extract audio log-mel feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from utils import extract_log_mel_features\n",
    "\n",
    "\n",
    "def load_audio_lm(audio_lm_path):\n",
    "    with open(audio_lm_path, 'rb') as fr:\n",
    "        audio_log_mel = pickle.load(fr)\n",
    "    audio_log_mel = audio_log_mel.detach()# [5, 1, 96, 64]\n",
    "    return audio_log_mel\n",
    "\n",
    "dataset_dir = '/mnt/data1/jiali/avsbench_synthesis_visual_random4/Single-source/s4_data/audio_wav'\n",
    "\n",
    "for split in ['test', 'train', 'val']:\n",
    "    base_dir = os.path.join(dataset_dir, split)\n",
    "    entries = os.listdir(base_dir)\n",
    "    categories = [entry for entry in entries if '.DS_Store' not in entry]\n",
    "    for temp_cate in categories:\n",
    "        print(split, temp_cate)\n",
    "        audio_list = os.listdir(os.path.join(base_dir, temp_cate))\n",
    "        for temp_audio in audio_list:\n",
    "            input_audio_path = os.path.join(base_dir, temp_cate, temp_audio)\n",
    "            log_mel_spectrogram = extract_log_mel_features(input_audio_path, n_mels=64, n_fft=2048, hop_length=512, num_frames=96)\n",
    "            \n",
    "            # Create the directory for saving if it doesn't exist\n",
    "            save_path1 = input_audio_path.replace('/audio_wav/', '/audio_log_mel/')\n",
    "            save_path = save_path1.replace('.wav', '.pkl')\n",
    "            \n",
    "            # Save the features\n",
    "            with open(save_path, 'wb') as f:  # Changed 'w' to 'wb' for binary write\n",
    "                pickle.dump(log_mel_spectrogram, f)\n",
    "\n",
    "            audio_log_mel = load_audio_lm(save_path)\n",
    "            print('audio_log_mel', audio_log_mel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesis MS3 (random 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. stitch frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from utils import stitch_frames_ms3\n",
    "import pandas as pd\n",
    "\n",
    "def get_split_from_video_id(csv_file, video_id):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Search for the row with the given video_id\n",
    "    row = df[df['video_id'] == video_id]\n",
    "    \n",
    "    # If the row is found, return the split value\n",
    "    if not row.empty:\n",
    "        return row['split'].values[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "base_dir = '/mnt/data1/jiali/avsbench_data/Multi-sources/ms3_data/visual_frames'\n",
    "csv_file = '/mnt/data1/jiali/avsbench_data/Multi-sources/ms3_meta_data.csv'\n",
    "\n",
    "video_list = os.listdir(base_dir)\n",
    "for temp_video in video_list:\n",
    "    input_video_path = os.path.join(base_dir, temp_video)\n",
    "    split = get_split_from_video_id(csv_file, temp_video) \n",
    "    stitch_frames_ms3(base_dir, input_video_path, split, csv_file, save_floder_name = '/avsbench_synthesis_visual_random4/',  num_with_audio_and_mask=random.randint(1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. extract audio log-mel feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def extract_log_mel_features(wav_path, n_mels=64, n_fft=1024, hop_length=512, num_frames=96, duration=5):\n",
    "    y, sr = librosa.load(wav_path, duration=duration)\n",
    "    \n",
    "    # 确保音频长度为5秒\n",
    "    if len(y) < sr * duration:\n",
    "        y = np.pad(y, (0, sr * duration - len(y)))\n",
    "    \n",
    "    # 分割音频为5个1秒的片段\n",
    "    y_segments = np.array_split(y, 5)\n",
    "    \n",
    "    log_mel_segments = []\n",
    "    for segment in y_segments:\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=segment, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length)\n",
    "        log_mel = librosa.power_to_db(mel_spectrogram)\n",
    "        log_mel = (log_mel - log_mel.mean()) / log_mel.std()\n",
    "        \n",
    "        # 调整时间帧数\n",
    "        if log_mel.shape[1] < num_frames:\n",
    "            pad_width = num_frames - log_mel.shape[1]\n",
    "            log_mel = np.pad(log_mel, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        elif log_mel.shape[1] > num_frames:\n",
    "            log_mel = log_mel[:, :num_frames]\n",
    "        \n",
    "        log_mel_segments.append(log_mel)\n",
    "    \n",
    "    # 堆叠5个片段\n",
    "    log_mel_stack = np.stack(log_mel_segments)\n",
    "    \n",
    "    # 转换为PyTorch张量并调整形状为 [5, 1, 96, 64]\n",
    "    log_mel_tensor = torch.from_numpy(log_mel_stack).float().permute(0, 2, 1).unsqueeze(1)\n",
    "    \n",
    "    return log_mel_tensor\n",
    "\n",
    "def load_audio_lm(audio_lm_path):\n",
    "    with open(audio_lm_path, 'rb') as fr:\n",
    "        audio_log_mel = pickle.load(fr)\n",
    "    audio_log_mel = audio_log_mel.detach()# [5, 1, 96, 64]\n",
    "    return audio_log_mel\n",
    "\n",
    "dataset_dir = '/mnt/data1/jiali/avsbench_synthesis_visual_random4/Multi-sources/ms3_data/audio_wav'\n",
    "\n",
    "for split in ['test', 'train', 'val']:\n",
    "    base_dir = os.path.join(dataset_dir, split)\n",
    "    audio_list = os.listdir(base_dir)\n",
    "    for temp_audio in audio_list:\n",
    "        input_audio_path = os.path.join(base_dir, temp_audio)\n",
    "        log_mel_spectrogram = extract_log_mel_features(input_audio_path, n_mels=64, n_fft=2048, hop_length=512, num_frames=96)\n",
    "        \n",
    "        # Create the directory for saving if it doesn't exist\n",
    "        save_path1 = input_audio_path.replace('/audio_wav/', '/audio_log_mel/')\n",
    "        save_path = save_path1.replace('.wav', '.pkl')\n",
    "        \n",
    "        # Save the features\n",
    "        with open(save_path, 'wb') as f:  # Changed 'w' to 'wb' for binary write\n",
    "            pickle.dump(log_mel_spectrogram, f)\n",
    "\n",
    "        audio_log_mel = load_audio_lm(save_path)\n",
    "        print('audio_log_mel', audio_log_mel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import extract_log_mel_features\n",
    "\n",
    "\n",
    "input_audio_path = '/home/jiali/AVSBench/synthesis_data/slience.wav'\n",
    "log_mel_spectrogram = extract_log_mel_features(input_audio_path, n_mels=64, n_fft=2048, hop_length=512, num_frames=96)\n",
    "save_path = input_audio_path.replace('.wav', '.pkl')\n",
    "with open(save_path, 'wb') as f:  # Changed 'w' to 'wb' for binary write\n",
    "    pickle.dump(log_mel_spectrogram, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Mel Tensor Shape: torch.Size([5, 1, 96, 64])\n",
      "Log Mel Tensor Values Range: tensor(0.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('/home/jiali/AVSBench/synthesis_data/slience.pkl', 'rb') as f:\n",
    "    log_mel_tensor  = pickle.load(f)\n",
    "\n",
    "print(\"Log Mel Tensor Shape:\", log_mel_tensor.shape)\n",
    "print(\"Log Mel Tensor Values Range:\", log_mel_tensor.min(), log_mel_tensor.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
